{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture we're going to talk about pattern matching in strings using regular expressions. Regular\n",
    "expressions, or regexes, are written in a condensed formatting language. In general, you can think of a\n",
    "regular expression as a pattern which you give to a regex processor with some source data. The processor then\n",
    "parses that source data using that pattern, and returns chunks of text back to the a data scientist or \n",
    "programmer for further manipulation. There's really three main reasons you would want to do this - to check\n",
    "whether a pattern exists within some source data, to get all instances of a complex pattern from some source\n",
    "data, or to clean your source data using a pattern generally through string splitting. Regexes are not\n",
    "trivial, but they are a foundational technique for data cleaning in data science applications, and a solid\n",
    "understanding of regexs will help you quickly and efficiently manipulate text data for further data science\n",
    "application.\n",
    "\n",
    "Now, you could teach a whole course on regular expressions alone, especially if you wanted to demystify how\n",
    "the regex parsing engine works and efficient mechanisms for parsing text. In this lecture I want to give you\n",
    "basic understanding of how regex works - enough knowledge that, with a little directed sleuthing, you'll be\n",
    "able to make sense of the regex patterns you see others use, and you can build up your practical knowledge of\n",
    "how to use regexes to improve your data cleaning. By the end of this lecture, you will understand the basics\n",
    "of regular expressions, how to define patterns for matching, how to apply these patterns to strings, and how\n",
    "to use the results of those patterns in data processing.\n",
    "\n",
    "Finally, a note that in order to best learn regexes you need to write regexes. I encourage you to stop the\n",
    "video at any time and try out new patterns or syntax you learn at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we'll import the re module, which is where python stores regular expression libraries.\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are several main processing functions in re that you might use. The first, match() checks for a match\n",
    "# that is at the beginning of the string and returns a boolean. Similarly, search(), checks for a match\n",
    "# anywhere in the string, and returns a boolean.\n",
    "\n",
    "# Lets create some text for an example\n",
    "text = \"This is a good day.\"\n",
    "\n",
    "# Now, lets see if it's a good day or not:\n",
    "if re.search(\"good\", text): # the first parameter here is the pattern\n",
    "    print(\"Wonderful!\")\n",
    "else:\n",
    "    print(\"Alas :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In addition to checking for conditionals, we can segment a string. The work that regex does here is called\n",
    "# tokenizing, where the string is separated into substrings based on patterns. Tokenizing is a core activity\n",
    "# in natural language processing, which we won't talk much about here but that you will study in the future\n",
    "\n",
    "# The findall() and split() functions will parse the string for us and return chunks. Lets try and example\n",
    "text = \"Amy works diligently. Amy gets good grades. Our student Amy is succesful.\"\n",
    "\n",
    "# This is a bit of a fabricated example, but lets split this on all instances of Amy\n",
    "re.split(\"Amy\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You'll notice that split has returned an empty string, followed by a number of statements about Amy, all as\n",
    "# elements of a list. If we wanted to count how many times we have talked about Amy, we could use findall()\n",
    "re.findall(\"Amy\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, so we've seen that .search() looks for some pattern and returns a boolean, that .split() will use a\n",
    "# pattern for creating a list of substrings, and that .findall() will look for a pattern and pull out all\n",
    "# occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we know how the python regex API works, lets talk about more complex patterns. The regex\n",
    "# specification standard defines a markup language to describe patterns in text. Lets start with anchors.\n",
    "# Anchors specify the start and/or the end of the string that you are trying to match. The caret character ^\n",
    "# means start and the dollar sign character $ means end. If you put ^ before a string, it means that the text\n",
    "# the regex processor retrieves must start with the string you specify. For ending, you have to put the $\n",
    "# character after the string, it means that the text Regex retrieves must end with the string you specify.\n",
    "\n",
    "# Here's an example\n",
    "text = \"Amy works diligently. Amy gets good grades. Our student Amy is succesful.\"\n",
    "\n",
    "# Lets see if this begins with Amy\n",
    "re.search(\"^Amy\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that re.search() actually returned to us a new object, called re.Match object. An re.Match object\n",
    "# always has a boolean value of True, as something was found, so you can always evaluate it in an if statement\n",
    "# as we did earlier. The rendering of the match object also tells you what pattern was matched, in this case\n",
    "# the word Amy, and the location the match was in, as the span."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patterns and Character Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's talk more about patterns and start with character classes. Let's create a string of a single learners'\n",
    "# grades over a semester in one course across all of their assignments\n",
    "grades=\"ACAAAABCBCBAA\"\n",
    "\n",
    "# If we want to answer the question \"How many B's were in the grade list?\" we would just use B\n",
    "re.findall(\"B\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we wanted to count the number of A's or B's in the list, we can't use \"AB\" since this is used to match\n",
    "# all A's followed immediately by a B. Instead, we put the characters A and B inside square brackets\n",
    "re.findall(\"[AB]\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is called the set operator. You can also include a range of characters, which are ordered\n",
    "# alphanumerically. For instance, if we want to refer to all lower case letters we could use [a-z] Lets build\n",
    "# a simple regex to parse out all instances where this student receive an A followed by a B or a C\n",
    "re.findall(\"[A][B-C]\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice how the [AB] pattern describes a set of possible characters which could be either (A OR B), while the\n",
    "# [A][B-C] pattern denoted two sets of characters which must have been matched back to back. You can write\n",
    "# this pattern by using the pipe operator, which means OR\n",
    "re.findall(\"AB|AC\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the caret with the set operator to negate our results. For instance, if we want to parse out only\n",
    "# the grades which were not A's\n",
    "re.findall(\"[^A]\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this carefully - the caret was previously matched to the beginning of a string as an anchor point, but\n",
    "# inside of the set operator the caret, and the other special characters we will be talking about, lose their\n",
    "# meaning. This can be a bit confusing. What do you think the result would be of this?\n",
    "re.findall(\"^[^A]\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's an empty list, because the regex says that we want to match any value at the beginning of the string\n",
    "# which is not an A. Our string though starts with an A, so there is no match found. And remember when you are\n",
    "# using the set operator you are doing character-based matching. So you are matching individual characters in\n",
    "# an OR method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, so we've talked about anchors and matching to the beginning and end of patterns. And we've talked about\n",
    "# characters and using sets with the [] notation. We've also talked about character negation, and how the pipe\n",
    "# | character allows us to or operations. Lets move on to quantifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantifiers are the number of times you want a pattern to be matched in order to match. The most basic\n",
    "# quantifier is expressed as e{m,n}, where e is the expression or character we are matching, m is the minimum\n",
    "# number of times you want it to matched, and n is the maximum number of times the item could be matched.\n",
    "\n",
    "# Let's use these grades as an example. How many times has this student been on a back-to-back A's streak?\n",
    "re.findall(\"A{2,10}\",grades) # we'll use 2 as our min, but ten as our max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we see that there were two streaks, one where the student had four A's, and one where they had only two\n",
    "# A's\n",
    "\n",
    "# We might try and do this using single values and just repeating the pattern\n",
    "re.findall(\"A{1,1}A{1,1}\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see, this is different than the first example. The first pattern is looking for any combination\n",
    "# of two A's up to ten A's in a row. So it sees four A's as a single streak. The second pattern is looking for\n",
    "# two A's back to back, so it sees two A's followed immediately by two more A's. We say that the regex\n",
    "# processor begins at the start of the string and consumes variables which match patterns as it does.\n",
    "\n",
    "# It's important to note that the regex quantifier syntax does not allow you to deviate from the {m,n}\n",
    "# pattern. In particular, if you have an extra space in between the braces you'll get an empty result\n",
    "re.findall(\"A{2, 2}\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And as we have already seen, if we don't include a quantifier then the default is {1,1}\n",
    "re.findall(\"AA\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oh, and if you just have one number in the braces, it's considered to be both m and n\n",
    "re.findall(\"A{2}\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this, we could find a decreasing trend in a student's grades\n",
    "re.findall(\"A{1,10}B{1,10}C{1,10}\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, that's a bit of a hack, because we included a maximum that was just arbitrarily large. There are three\n",
    "# other quantifiers that are used as short hand, an asterix * to match 0 or more times, a question mark ? to\n",
    "# match one or more times, or a + plus sign to match one or more times. Lets look at a more complex example,\n",
    "# and load some data scraped from wikipedia\n",
    "with open(\"datasets/ferpa.txt\",\"r\") as file:\n",
    "    # we'll read that into a variable called wiki\n",
    "    wiki=file.read()\n",
    "# and lets print that variable out to the screen\n",
    "wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scanning through this document one of the things we notice is that the headers all have the words [edit]\n",
    "# behind them, followed by a newline character. So if we wanted to get a list of all of the headers in this\n",
    "# article we could do so using re.findall\n",
    "re.findall(\"[a-zA-Z]{1,100}\\[edit\\]\",wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, that didn't quite work. It got all of the headers, but only the last word of the header, and it really\n",
    "# was quite clunky. Lets iteratively improve this. First, we can use \\w to match any letter, including digits\n",
    "# and numbers.\n",
    "re.findall(\"[\\w]{1,100}\\[edit\\]\",wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is something new. \\w is a metacharacter, and indicates a special pattern of any letter or digit. There\n",
    "# are actually a number of different metacharacters listed in the documentation. For instance, \\s matches any\n",
    "# whitespace character.\n",
    "\n",
    "# Next, there are three other quantifiers we can use which shorten up the curly brace syntax. We can use an\n",
    "# asterix * to match 0 or more times, so let's try that.\n",
    "re.findall(\"[\\w]*\\[edit\\]\",wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have shortened the regex, let's improve it a little bit. We can add in a spaces using the space\n",
    "# character\n",
    "re.findall(\"[\\w ]*\\[edit\\]\",wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, so this gets us the list of section titles in the wikipedia page! You can now create a list of titles by\n",
    "# iterating through this and applying another regex\n",
    "for title in re.findall(\"[\\w ]*\\[edit\\]\",wiki):\n",
    "    # Now we will take that intermediate result and split on the square bracket [ just taking the first result\n",
    "    print(re.split(\"[\\[]\",title)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, this works, but it's a bit of a pain. To this point we have been talking about a regex as a single\n",
    "# pattern which is matched. But, you can actually match different patterns, called groups, at the same time,\n",
    "# and then refer to the groups you want. To group patterns together you use parentheses, which is actually\n",
    "# pretty natural. Lets rewrite our findall using groups\n",
    "re.findall(\"([\\w ]*)(\\[edit\\])\",wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice - we see that the python re module breaks out the result by group. We can actually refer to groups by\n",
    "# number as well with the match objects that are returned. But, how do we get back a list of match objects?\n",
    "# Thus far we've seen that findall() returns strings, and search() and match() return individual Match\n",
    "# objects. But what do we do if we want a list of Match objects? In this case, we use the function finditer()\n",
    "for item in re.finditer(\"([\\w ]*)(\\[edit\\])\",wiki):\n",
    "    print(item.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see here that the groups() method returns a tuple of the group. We can get an individual group using\n",
    "# group(number), where group(0) is the whole match, and each other number is the portion of the match we are\n",
    "# interested in. In this case, we want group(1)\n",
    "for item in re.finditer(\"([\\w ]*)(\\[edit\\])\",wiki):\n",
    "    print(item.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One more piece to regex groups that I rarely use but is a good idea is labeling or naming groups. In the\n",
    "# previous example I showed you how you can use the position of the group. But giving them a label and looking\n",
    "# at the results as a dictionary is pretty useful. For that we use the syntax (?P<name>), where the parethesis\n",
    "# starts the group, the ?P indicates that this is an extension to basic regexes, and <name> is the dictionary\n",
    "# key we want to use wrapped in <>.\n",
    "for item in re.finditer(\"(?P<title>[\\w ]*)(?P<edit_link>\\[edit\\])\",wiki):\n",
    "    # We can get the dictionary returned for the item with .groupdict()\n",
    "    print(item.groupdict()['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Of course, we can print out the whole dictionary for the item too, and see that the [edit] string is still\n",
    "# in there. Here's the dictionary kept for the last match\n",
    "print(item.groupdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, we have seen how we can match individual character patterns with [], how we can group matches together\n",
    "# using (), and how we can use quantifiers such as *, ?, or m{n} to describe patterns. Something I glossed\n",
    "# over in the previous example was the \\w, which standards for any word character. There are a number of\n",
    "# short hands which are used with regexes for different kinds of characters, including:\n",
    "# a . for any single character which is not a newline\n",
    "# a \\d for any digit\n",
    "# and \\s for any whitespace character, like spaces and tabs\n",
    "# There are more, and a full list can be found in the python documentation for regexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look-ahead and Look-behind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One more concept to be familiar with is called \"look ahead\" and \"look behind\" matching. In this case, the\n",
    "# pattern being given to the regex engine is for text either before or after the text we are trying to\n",
    "# isolate. For example, in our headers we want to isolate text which  comes before the [edit] rendering, but\n",
    "# we actually don't care about the [edit] text itself. Thus far we have been throwing the [edit] away, but if\n",
    "# we want to use them to match but don't want to capture them we could put them in a group and use look ahead\n",
    "# instead with ?= syntax\n",
    "for item in re.finditer(\"(?P<title>[\\w ]+)(?=\\[edit\\])\",wiki):\n",
    "    # What this regex says is match two groups, the first will be named and called title, will have any amount\n",
    "    # of whitespace or regular word characters, the second will be the characters [edit] but we don't actually\n",
    "    # want this edit put in our output match objects\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Wikipedia Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at some more wikipedia data. Here's some data on universities in the US which are buddhist-based\n",
    "with open(\"datasets/buddhist.txt\",\"r\") as file:\n",
    "    # we'll read that into a variable called wiki\n",
    "    wiki=file.read()\n",
    "# and lets print that variable out to the screen\n",
    "wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that each university follows a fairly similar pattern, with the name followed by an – then the\n",
    "# words \"located in\" followed by the city and state\n",
    "\n",
    "# I'll actually use this example to show you the verbose mode of python regexes. The verbose mode allows you\n",
    "# to write multi-line regexes and increases readability. For this mode, we have to explicitly indicate all\n",
    "# whitespace characters, either by prepending them with a \\ or by using the \\s special value. However, this\n",
    "# means we can write our regex a bit more like code, and can even include comments with #\n",
    "pattern=\"\"\"\n",
    "(?P<title>.*)        #the university title\n",
    "(–\\ located\\ in\\ )   #an indicator of the location\n",
    "(?P<city>\\w*)        #city the university is in\n",
    "(,\\ )                #separator for the state\n",
    "(?P<state>\\w*)       #the state the city is located in\"\"\"\n",
    "\n",
    "# Now when we call finditer() we just pass the re.VERBOSE flag as the last parameter, this makes it much\n",
    "# easier to understand large regexes!\n",
    "for item in re.finditer(pattern,wiki,re.VERBOSE):\n",
    "    # We can get the dictionary returned for the item with .groupdict()\n",
    "    print(item.groupdict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: New York Times and Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's another example from the New York Times which covers health tweets on news items. This data came from\n",
    "# the UC Irvine Machine Learning Repository which is a great source of different kinds of data\n",
    "with open(\"datasets/nytimeshealth.txt\",\"r\") as file:\n",
    "    # We'll read everything into a variable and take a look at it\n",
    "    health=file.read()\n",
    "health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So here we can see there are tweets with fields separated by pipes |. Lets try and get a list of all of the\n",
    "# hashtags that are included in this data. A hashtag begins with a pound sign (or hash mark) and continues\n",
    "# until some whitespace is found\n",
    "\n",
    "# So lets create a pattern. We want to include the hash sign first, then any number of alphanumeric\n",
    "# characters. And we end when we see some whitespace\n",
    "pattern = '#[\\w\\d]*(?=\\s)'\n",
    "\n",
    "# Notice that the ending is a look ahead. We're not actually interested in matching whitespace in the return\n",
    "# value. Also notice that I use an asterix * instead of the plus + for the matching of alphabetical characters\n",
    "# or digits, because a + would require at least one of each\n",
    "\n",
    "# Lets searchg and display all of the hashtags\n",
    "re.findall(pattern, health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see here that there were lots of ebola related tweeks in this particular dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lecture has been an overview of regular expressions, and really, we've just scratched the surface of what \n",
    "you can do. Now, I actually find regex's really frustrating - they're incredibly powerful, but if you don't\n",
    "use them for awhile you're left grasping for memory of some of the details, especially named groups and look\n",
    "ahead searches. But, there are lots of great examples and reference guides on the web, including the python\n",
    "documentation for regex, and with these in hand you should be able to write concise and readable code which\n",
    "performs well too. Having basic regex literacy is a core skill for applied data scientists. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
